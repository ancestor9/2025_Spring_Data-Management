{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancestor9/2025_Spring_Data-Management/blob/main/week_06/Text_Representation_and_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUYhh4devHeN"
      },
      "source": [
        "# í…ìŠ¤íŠ¸ í‘œí˜„ ê¸°ë²•ê³¼ ì„ë² ë”©\n",
        "# **Data Representation**\n",
        "\n",
        "## 1. Tabular data\n",
        "<img src='http://jalammar.github.io/images/pandas-intro/0%20excel-to-pandas.png'>\n",
        "\n",
        "## 2. Audio and Timeseries data\n",
        "<img src= 'http://jalammar.github.io/images/numpy/numpy-audio.png'>\n",
        "\n",
        "## 3. Image data\n",
        "<img src='http://jalammar.github.io/images/numpy/numpy-grayscale-image.png'>\n",
        "<img src='http://jalammar.github.io/images/numpy/numpy-color-image.png'>\n",
        "\n",
        "## <font color='orange'>**4. Text data**\n",
        "- **ì•„ë˜ ê·¸ë¦¼ì„ ì´í•´í•˜ì—¬ì•¼ í•œë‹¤.**\n",
        "<img src='http://jalammar.github.io/images/numpy/numpy-nlp-embeddings.png'>\n",
        "<img src='http://jalammar.github.io/images/numpy/numpy-nlp-bert-shape.png'>\n",
        "\n",
        "\n",
        "## <font color='orange'>**ëª©ì†Œë¦¬, ì£¼ì‹ê°€ê²©, ê·¸ë¦¼, ë™ì˜ìƒ, ì–¸ì–´ëŠ” ëª¨ë‘ ìˆœì„œ(Order)ê°€ ìˆë‹¤.**"
      ],
      "id": "cUYhh4devHeN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33pJFFSjvHeQ"
      },
      "source": [
        "## ğŸ¯ ê°•ì˜ ëª©í‘œ\n",
        "- ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ì‚¬ìš©ë˜ëŠ” í…ìŠ¤íŠ¸ í‘œí˜„ ë°©ë²•ì˜ ì—­ì‚¬ì™€ ì›ë¦¬ë¥¼ ì´í•´í•œë‹¤.\n",
        "- Bag of Words, TF-IDF, Word Embedding ê¸°ë²•ì„ ì‹¤ìŠµí•œë‹¤.\n",
        "- Word2Vecê³¼ ê°™ì€ ì‚¬ì „ í•™ìŠµëœ ì„ë² ë”©ì„ ì ìš©í•´ ë³¸ë‹¤."
      ],
      "id": "33pJFFSjvHeQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSCZdepMvHeR"
      },
      "source": [
        "## ğŸ“˜ ì´ë¡  ê°•ì˜\n",
        "### **1. í…ìŠ¤íŠ¸ í‘œí˜„(Representation of Text)ì˜ í•„ìš”ì„±**\n",
        "- ì»´í“¨í„°ëŠ” í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ì´í•´í•´ì•¼ í•¨\n",
        "- ìì—°ì–´ëŠ” ë¹„ì •í˜• ë°ì´í„° â†’ ìˆ˜ì¹˜í™” í•„ìš”\n",
        "\n",
        "### **2. í…ìŠ¤íŠ¸ í‘œí˜„ ë°©ì‹**\n",
        "#### 2.1 One-hot Encoding\n",
        "- ê° ë‹¨ì–´ë¥¼ ê³ ìœ  ì¸ë±ìŠ¤ë¡œ ë³€í™˜ í›„, ê·¸ ì¸ë±ìŠ¤ë§Œ 1ì¸ ë²¡í„°ë¡œ í‘œí˜„\n",
        "- ë‹¨ì : í¬ì†Œì„±, ë‹¨ì–´ ê°„ ì˜ë¯¸ ê´€ê³„ ì—†ìŒ\n",
        "\n",
        "#### 2.2 Bag of Words (BoW)\n",
        "- ë¬¸ì„œë³„ ë‹¨ì–´ ì¶œí˜„ ë¹ˆë„ ë²¡í„°\n",
        "- ì¥ì : ë‹¨ìˆœí•˜ê³  ë¹ ë¦„\n",
        "- ë‹¨ì : ë¬¸ë§¥ ì •ë³´ ì†ì‹¤\n",
        "- ğŸ“Œ êµ¬í˜„ ë„êµ¬: `CountVectorizer`\n",
        "\n",
        "#### 2.3 N-gram ëª¨ë¸\n",
        "- ì—°ì†ëœ Nê°œì˜ ë‹¨ì–´ë¥¼ í•˜ë‚˜ì˜ íŠ¹ì§•ìœ¼ë¡œ ê°„ì£¼\n",
        "- ì˜ˆ: bigram(\"I love NLP\") â†’ [\"I love\", \"love NLP\"]\n",
        "- ğŸ“Œ êµ¬í˜„ ë„êµ¬: `CountVectorizer(ngram_range=(n, n))`\n",
        "\n",
        "#### 2.4 TF-IDF\n",
        "- ë‹¨ì–´ì˜ ì¤‘ìš”ë„ë¥¼ ë°˜ì˜í•œ ë²¡í„°\n",
        "- TF: ë¬¸ì„œ ë‚´ ë¹ˆë„ / IDF: ì „ì²´ ë¬¸ì„œì—ì„œì˜ í¬ê·€ì„±\n",
        "- ğŸ“Œ êµ¬í˜„ ë„êµ¬: `TfidfVectorizer`\n",
        "\n",
        "#### 2.5 Word Embedding\n",
        "- ì˜ë¯¸ ê¸°ë°˜ ë¶„ì‚° í‘œí˜„ (Distributed Representation)\n",
        "- Word2Vec, GloVe, FastText ë“±\n",
        "- ë‹¨ì–´ ê°„ ìœ ì‚¬ë„, ì˜ë¯¸ ì¶”ë¡  ê°€ëŠ¥\n",
        "- CBOW / Skip-gram\n",
        "\n",
        "#### 2.6 ì‚¬ì „í•™ìŠµ ì„ë² ë”©\n",
        "- Gensim / HuggingFace Transformers ì‚¬ìš© ê°€ëŠ¥\n",
        "- ì˜ˆ: word2vec-google-news-300"
      ],
      "id": "lSCZdepMvHeR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxdzGGhUvHeS"
      },
      "source": [
        "## ğŸ’» **ì‹¤ìŠµ**\n",
        "\n",
        "#### 2.0 Integer Encoding\n",
        "- ğŸ“Œ êµ¬í˜„ ë„êµ¬: `Tokenizer`\n"
      ],
      "id": "RxdzGGhUvHeS"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61FcFWOSxr5r"
      },
      "id": "61FcFWOSxr5r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 2.1 One-hot Encoding\n",
        "- ğŸ“Œ êµ¬í˜„ ë„êµ¬: `CountVectorizer`\n",
        "\n",
        "#### 2.2 Bag of Words (BoW)\n",
        "- ğŸ“Œ êµ¬í˜„ ë„êµ¬: `CountVectorizer`\n",
        "\n",
        "#### 2.3 N-gram ëª¨ë¸\n",
        "- ğŸ“Œ êµ¬í˜„ ë„êµ¬: `CountVectorizer(ngram_range=(n, n))`\n",
        "\n",
        "#### 2.4 TF-IDF\n",
        "- ğŸ“Œ êµ¬í˜„ ë„êµ¬: `TfidfVectorizer`\n",
        "\n",
        "#### 2.5 Word Embedding\n",
        "- ğŸ“Œ êµ¬í˜„ ë„êµ¬: 'Word2Vec, GloVe, FastText, CBOW / Skip-gram'\n",
        "\n",
        "#### 2.6 ì‚¬ì „í•™ìŠµ ì„ë² ë”©\n",
        "- ğŸ“Œ êµ¬í˜„ ë„êµ¬: Gensim / HuggingFace Transformers(word2vec-google-news-300)"
      ],
      "metadata": {
        "id": "Ki75EqrkxogK"
      },
      "id": "Ki75EqrkxogK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKO4QgTuvHeS"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "docs = [\n",
        "    \"I love natural language processing\",\n",
        "    \"Language models are amazing\",\n",
        "    \"I enjoy learning about embeddings\",\n",
        "    \"Embeddings capture semantic meaning\",\n",
        "    \"Natural language is complex\"\n",
        "]\n",
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(docs)\n",
        "print(\"BoW Feature Names:\", vectorizer.get_feature_names_out())\n",
        "print(\"BoW Matrix:\\n\", bow.toarray())"
      ],
      "id": "DKO4QgTuvHeS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Q8LjfCvHeT"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(docs)\n",
        "print(\"TF-IDF Feature Names:\", tfidf.get_feature_names_out())\n",
        "print(\"TF-IDF Matrix:\\n\", tfidf_matrix.toarray())"
      ],
      "id": "I-Q8LjfCvHeT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEmcqoiuvHeT"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "vectorizer_bigram = CountVectorizer(ngram_range=(2,2))\n",
        "bow_bigram = vectorizer_bigram.fit_transform(docs)\n",
        "print(\"Bi-gram Feature Names:\", vectorizer_bigram.get_feature_names_out())\n",
        "print(\"Bi-gram BoW Matrix:\\n\", bow_bigram.toarray())"
      ],
      "id": "XEmcqoiuvHeT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpIVnr9xvHeU"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "tokenized_docs = [doc.lower().split() for doc in docs]\n",
        "w2v_model = Word2Vec(sentences=tokenized_docs, vector_size=100, window=3, min_count=1, sg=1)\n",
        "print(\"Vector for 'language':\", w2v_model.wv['language'])\n",
        "print(\"Similarity between 'language' and 'natural':\", w2v_model.wv.similarity('language', 'natural'))\n",
        "print(\"Most similar to 'embeddings':\", w2v_model.wv.most_similar('embeddings', topn=3))"
      ],
      "id": "IpIVnr9xvHeU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqlWKH_HvHeU"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "print(model['computer'])\n",
        "print(model.most_similar(\"language\"))\n",
        "print(\"Similarity between 'language' and 'computer':\", model.similarity('language', 'computer'))"
      ],
      "id": "bqlWKH_HvHeU"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}