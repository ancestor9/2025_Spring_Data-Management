## similarity_metrics
### 참고자료 : https://wikidocs.net/127857
- 09장 자연어 처리와 토큰화, 수치화, 수량화에 의한 정보표현(Representation Learning)
  1. 텍스트 자료의 토큰화 (단어나 문장의 Tokenization)
  2. 텍스트 자료의 수치화 (단어의 수치화, Onehotencoding, BOW)
  3. 문서의 수량화 (TF, DF-IDF)
  4. 코사인유사도 기반의 문서 유사도 (Cosine Similarity)

![Wprd Embeddings](https://velog.velcdn.com/images/leeebs/post/f3b865fc-44c0-4be6-9490-9e07cec7a860/image.png)


![Vector Embeddings](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*_XDfq2rwgYYSB1OgNh1bzw.png)

https://zilliz.com/blog/similarity-metrics-for-vector-search

## Pause to think!
### 1. Why do you use log in the area of machine learning ? 
### 2. Why do you use inner product in Linear Algebra?
### 3. What is the difference between 2/10 and 2000/10000 ?
### 4. How to apply the webcrawling technique to Feature Engineering?


## Naver API, 공공데이터 API, Google News API
